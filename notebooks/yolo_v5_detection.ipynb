{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Object Detection and OCR Evaluation Pipeline\n",
    "This notebook demonstrates a complete pipeline for object detection using YOLOv5 and Optical Character Recognition (OCR) using EasyOCR. The steps include performing object detection, cropping detected objects, applying OCR, and evaluating the OCR results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setting Up the Environment\n",
    "We start by importing the necessary libraries, including YOLOv5 for object detection, EasyOCR for OCR, OpenCV for image processing, and Pandas for data manipulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "import torch\n",
    "import os\n",
    "import yaml\n",
    "import cv2\n",
    "import json\n",
    "import pandas as pd\n",
    "import random\n",
    "import easyocr\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define the directories for the YOLOv5 model weights, dataset, and output locations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_dir = os.path.dirname(os.getcwd())\n",
    "yolo_location = os.path.join(project_dir, 'yolov5')\n",
    "dataset_location = os.path.join(project_dir, 'data', 'ocr_evaluation')\n",
    "weights_location = os.path.join(project_dir, 'notebooks', 'yoloV5_model_weights')\n",
    "\n",
    "output_location = os.path.join(project_dir, 'data', 'yolo_v5')\n",
    "output_name = 'detection_results'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Performing Object Detection\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We run the YOLOv5 detection script to detect objects in the dataset images. The results are saved in the specified output directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/roma/5sem/Real-time_Number_Plate_Recognition/yolov5\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/home/roma/5sem/Real-time_Number_Plate_Recognition/notebooks/yoloV5_model_weights/best.pt'], source=/home/roma/5sem/Real-time_Number_Plate_Recognition/data/ocr_evaluation, data=data/coco128.yaml, imgsz=[416, 416], conf_thres=0.4, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=True, save_format=0, save_csv=False, save_conf=True, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=/home/roma/5sem/Real-time_Number_Plate_Recognition/data/yolo_v5, name=detection_results, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLOv5 ðŸš€ 2024-10-21 Python-3.12.7 torch-2.5.1+cu124 CUDA:0 (NVIDIA GeForce RTX 3060 Laptop GPU, 5830MiB)\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s_custom summary: 157 layers, 7012822 parameters, 0 gradients, 15.8 GFLOPs\n",
      "image 1/395 /home/roma/5sem/Real-time_Number_Plate_Recognition/data/ocr_evaluation/00000.jpg: 320x416 1 License_Plate, 37.2ms\n",
      "image 2/395 /home/roma/5sem/Real-time_Number_Plate_Recognition/data/ocr_evaluation/00014.jpg: 320x416 1 License_Plate, 4.7ms\n",
      "image 3/395 /home/roma/5sem/Real-time_Number_Plate_Recognition/data/ocr_evaluation/00015.jpg: 320x416 1 License_Plate, 10.8ms\n",
      "image 4/395 /home/roma/5sem/Real-time_Number_Plate_Recognition/data/ocr_evaluation/00016.jpg: 320x416 1 License_Plate, 4.4ms\n",
      "image 5/395 /home/roma/5sem/Real-time_Number_Plate_Recognition/data/ocr_evaluation/00022.jpg: 320x416 1 License_Plate, 4.4ms\n",
      "image 6/395 /home/roma/5sem/Real-time_Number_Plate_Recognition/data/ocr_evaluation/00024.jpg: 320x416 1 License_Plate, 4.4ms\n",
      "image 7/395 /home/roma/5sem/Real-time_Number_Plate_Recognition/data/ocr_evaluation/00035.jpg: 320x416 2 License_Plates, 9.9ms\n",
      "image 8/395 /home/roma/5sem/Real-time_Number_Plate_Recognition/data/ocr_evaluation/00037.jpg: 320x416 1 License_Plate, 10.3ms\n",
      "image 9/395 /home/roma/5sem/Real-time_Number_Plate_Recognition/data/ocr_evaluation/00038.jpg: 320x416 1 License_Plate, 11.2ms\n",
      "image 10/395 /home/roma/5sem/Real-time_Number_Plate_Recognition/data/ocr_evaluation/00039.jpg: 320x416 1 License_Plate, 11.6ms\n",
      "image 11/395 /home/roma/5sem/Real-time_Number_Plate_Recognition/data/ocr_evaluation/00075.jpg: 320x416 2 License_Plates, 4.4ms\n",
      "image 12/395 /home/roma/5sem/Real-time_Number_Plate_Recognition/data/ocr_evaluation/00076.jpg: 320x416 1 License_Plate, 4.7ms\n",
      "image 13/395 /home/roma/5sem/Real-time_Number_Plate_Recognition/data/ocr_evaluation/00077.jpg: 320x416 2 License_Plates, 4.8ms\n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/roma/5sem/Real-time_Number_Plate_Recognition/yolov5/detect.py\", line 437, in <module>\n",
      "    main(opt)\n",
      "  File \"/home/roma/5sem/Real-time_Number_Plate_Recognition/yolov5/detect.py\", line 432, in main\n",
      "    run(**vars(opt))\n",
      "  File \"/home/roma/5sem/Real-time_Number_Plate_Recognition/.venv/lib/python3.12/site-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/roma/5sem/Real-time_Number_Plate_Recognition/yolov5/detect.py\", line 185, in run\n",
      "    for path, im, im0s, vid_cap, s in dataset:\n",
      "                                      ^^^^^^^\n",
      "  File \"/home/roma/5sem/Real-time_Number_Plate_Recognition/yolov5/utils/dataloaders.py\", line 396, in __next__\n",
      "    im0 = cv2.imread(path)  # BGR\n",
      "          ^^^^^^^^^^^^^^^^\n",
      "  File \"/home/roma/5sem/Real-time_Number_Plate_Recognition/yolov5/utils/general.py\", line 1274, in imread\n",
      "    return cv2.imdecode(np.fromfile(filename, np.uint8), flags)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "%cd {yolo_location}\n",
    "!python detect.py --weights {weights_location}/best.pt --img 416 --conf 0.4 --source {dataset_location} --save-txt --save-conf --project {output_location} --name {output_name}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We iterate over the detected objects, crop them from the source images, and save the cropped images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File not found: /home/roma/5sem/Real-time_Number_Plate_Recognition/data/yolo_v5/detection_results/labels/00591.txt\n",
      "File not found: /home/roma/5sem/Real-time_Number_Plate_Recognition/data/yolo_v5/detection_results/labels/01026.txt\n",
      "File not found: /home/roma/5sem/Real-time_Number_Plate_Recognition/data/yolo_v5/detection_results/labels/01803.txt\n",
      "File not found: /home/roma/5sem/Real-time_Number_Plate_Recognition/data/yolo_v5/detection_results/labels/01003.txt\n",
      "File not found: /home/roma/5sem/Real-time_Number_Plate_Recognition/data/yolo_v5/detection_results/labels/00440.txt\n",
      "File not found: /home/roma/5sem/Real-time_Number_Plate_Recognition/data/yolo_v5/detection_results/labels/01595.txt\n",
      "File not found: /home/roma/5sem/Real-time_Number_Plate_Recognition/data/yolo_v5/detection_results/labels/00573.txt\n",
      "File not found: /home/roma/5sem/Real-time_Number_Plate_Recognition/data/yolo_v5/detection_results/labels/00741.txt\n",
      "File not found: /home/roma/5sem/Real-time_Number_Plate_Recognition/data/yolo_v5/detection_results/labels/00236.txt\n",
      "File not found: /home/roma/5sem/Real-time_Number_Plate_Recognition/data/yolo_v5/detection_results/labels/00776.txt\n",
      "File not found: /home/roma/5sem/Real-time_Number_Plate_Recognition/data/yolo_v5/detection_results/labels/00478.txt\n",
      "File not found: /home/roma/5sem/Real-time_Number_Plate_Recognition/data/yolo_v5/detection_results/labels/00742.txt\n",
      "File not found: /home/roma/5sem/Real-time_Number_Plate_Recognition/data/yolo_v5/detection_results/labels/01831.txt\n",
      "File not found: /home/roma/5sem/Real-time_Number_Plate_Recognition/data/yolo_v5/detection_results/labels/01821.txt\n",
      "File not found: /home/roma/5sem/Real-time_Number_Plate_Recognition/data/yolo_v5/detection_results/labels/00816.txt\n",
      "File not found: /home/roma/5sem/Real-time_Number_Plate_Recognition/data/yolo_v5/detection_results/labels/00669.txt\n",
      "File not found: /home/roma/5sem/Real-time_Number_Plate_Recognition/data/yolo_v5/detection_results/labels/00771.txt\n",
      "File not found: /home/roma/5sem/Real-time_Number_Plate_Recognition/data/yolo_v5/detection_results/labels/00247.txt\n",
      "File not found: /home/roma/5sem/Real-time_Number_Plate_Recognition/data/yolo_v5/detection_results/labels/00814.txt\n",
      "File not found: /home/roma/5sem/Real-time_Number_Plate_Recognition/data/yolo_v5/detection_results/labels/00615.txt\n",
      "File not found: /home/roma/5sem/Real-time_Number_Plate_Recognition/data/yolo_v5/detection_results/labels/00624.txt\n",
      "File not found: /home/roma/5sem/Real-time_Number_Plate_Recognition/data/yolo_v5/detection_results/labels/00132.txt\n",
      "File not found: /home/roma/5sem/Real-time_Number_Plate_Recognition/data/yolo_v5/detection_results/labels/00786.txt\n",
      "File not found: /home/roma/5sem/Real-time_Number_Plate_Recognition/data/yolo_v5/detection_results/labels/00393.txt\n",
      "File not found: /home/roma/5sem/Real-time_Number_Plate_Recognition/data/yolo_v5/detection_results/labels/00958.txt\n",
      "File not found: /home/roma/5sem/Real-time_Number_Plate_Recognition/data/yolo_v5/detection_results/labels/00716.txt\n",
      "File not found: /home/roma/5sem/Real-time_Number_Plate_Recognition/data/yolo_v5/detection_results/labels/00348.txt\n"
     ]
    }
   ],
   "source": [
    "input_img_dir = dataset_location\n",
    "input_txt_dir = f\"{output_location}/{output_name}/labels\"\n",
    "output_dir = f'{output_location}/cropped_plates'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "for img_file in os.listdir(input_img_dir):\n",
    "    if img_file.endswith('jpg'):\n",
    "        img_path = os.path.join(input_img_dir, img_file)\n",
    "        img = cv2.imread(img_path)\n",
    "        img_height, img_width = img.shape[:2]\n",
    "\n",
    "        txt_path = os.path.join(input_txt_dir, img_file[:-3]+'txt')\n",
    "        try:\n",
    "            with open(txt_path, 'r') as f:\n",
    "                max_conf = -1.0\n",
    "                for line in f.readlines():\n",
    "                    class_id, x_center, y_center, width, height, conf = map(float, line.split())\n",
    "                    x_center *= img_width\n",
    "                    y_center *= img_height\n",
    "                    width *= img_width\n",
    "                    height *= img_height\n",
    "\n",
    "                    x1 = int(x_center - width / 2)\n",
    "                    y1 = int(y_center - height / 2)\n",
    "                    x2 = int(x_center + width / 2)\n",
    "                    y2 = int(y_center + height / 2)\n",
    "                    cropped_plate = img[y1:y2, x1:x2]\n",
    "\n",
    "                    # save plate with the highest confidence\n",
    "                    if conf > max_conf:\n",
    "                        plate_save_path = os.path.join(output_dir, f'plate_{img_file}')\n",
    "                        cv2.imwrite(plate_save_path, cropped_plate)\n",
    "                        max_conf = conf\n",
    "        except FileNotFoundError:\n",
    "            print(f\"File not found: {txt_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
