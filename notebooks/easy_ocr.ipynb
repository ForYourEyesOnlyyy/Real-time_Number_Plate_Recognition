{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "import torch\n",
    "import os\n",
    "import yaml\n",
    "import cv2\n",
    "import json\n",
    "import pandas as pd\n",
    "import random\n",
    "import easyocr\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_dir = os.path.dirname(os.getcwd())\n",
    "yolo_location = os.path.join(project_dir, 'yolov5')\n",
    "dataset_location = os.path.join(project_dir, 'data', 'ocr_evaluation')\n",
    "weights_location = os.path.join(project_dir, 'yoloV5_model_weights')\n",
    "\n",
    "output_location = os.path.join(project_dir, 'data', 'yolo_v5')\n",
    "output_name = 'detection_results'\n",
    "\n",
    "input_img_dir = dataset_location\n",
    "input_txt_dir = f\"{output_location}/{output_name}/labels\"\n",
    "output_dir = f'{output_location}/cropped_plates'\n",
    "os.makedirs(output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = easyocr.Reader(['en'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_dataset_location = dataset_location\n",
    "cropped_dataset_location = output_dir\n",
    "results_dir = f\"{output_location}/ocr_results\"\n",
    "scale_dataset_location = f\"{output_location}/scaled_plates\"\n",
    "cropped_dataset_location\n",
    "\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "os.makedirs(scale_dataset_location, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for img_file in os.listdir(cropped_dataset_location):\n",
    "    if img_file.endswith('jpg'):\n",
    "        img_path = os.path.join(cropped_dataset_location, img_file)\n",
    "\n",
    "        img = cv2.imread(img_path)\n",
    "\n",
    "        output_path = os.path.join(scale_dataset_location, img_file)\n",
    "        cv2.imwrite(output_path, cv2.cvtColor(img, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "        result = reader.readtext(output_path)\n",
    "    \n",
    "        output_txt_path = os.path.join(results_dir, img_file[:-3]+'json')\n",
    "        with open(output_txt_path, 'w') as f:\n",
    "            dict_lst = []\n",
    "            for (bbox, text, prob) in result:\n",
    "                dict_lst.append({'Text' : text, 'Probability' : prob})\n",
    "            json.dump(dict_lst, f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Evaluating OCR Results\n",
    "\n",
    "We load the ground truth data from a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_true_location = f'{dataset_location}/output.csv'\n",
    "df_true = pd.read_csv(df_true_location)\n",
    "df_true['picture_name'] = df_true['picture_name'].apply(lambda x: 'plate_'+x)\n",
    "df_true.set_index('picture_name', inplace=True)\n",
    "df_true.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred_location = f'{output_location}/pred.csv'\n",
    "plate_numbers = []\n",
    "plate_strings = []\n",
    "\n",
    "threshold = 0.6\n",
    "\n",
    "for ocr_file in os.listdir(results_dir):\n",
    "    with open(os.path.join(results_dir, ocr_file), 'r') as f:\n",
    "        plt_str = ''\n",
    "        results = json.load(f)\n",
    "        for result in results:\n",
    "            if float(result['Probability']) > threshold:\n",
    "                plt_str += result['Text']\n",
    "        plt_str = plt_str.replace(\" \", \"\").upper()\n",
    "        plate_strings.append(plt_str)\n",
    "        plate_numbers.append(ocr_file.split('.')[0]+'.jpg')\n",
    "\n",
    "df_pred = pd.DataFrame({'picture_name':plate_numbers, 'text':plate_strings})\n",
    "df_pred.to_csv(df_pred_location)\n",
    "df_pred.set_index('picture_name', inplace=True)\n",
    "df_pred.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We evaluate the OCR performance using accuracy, Levenshtein ratio, and character-level precision, recall, and F1 score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from difflib import SequenceMatcher\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "\n",
    "# Merging dataframes on 'picture_name' index to only evaluate overlapping entries\n",
    "df_merged = df_true.join(df_pred, lsuffix='_true', rsuffix='_pred', how='inner')\n",
    "\n",
    "# 1. Accuracy (Exact Match)\n",
    "exact_matches = (df_merged['text_true'] == df_merged['text_pred']).sum()\n",
    "accuracy = exact_matches / len(df_merged)\n",
    "\n",
    "# 2. Levenshtein Distance (Edit Distance) - Using SequenceMatcher\n",
    "def levenshtein_ratio(str1, str2):\n",
    "    return SequenceMatcher(None, str1, str2).ratio()\n",
    "\n",
    "df_merged['levenshtein_ratio'] = df_merged.apply(lambda row: levenshtein_ratio(row['text_true'], row['text_pred']), axis=1)\n",
    "average_levenshtein_ratio = df_merged['levenshtein_ratio'].mean()\n",
    "\n",
    "# 3. Character-Level Precision, Recall, F1 Score\n",
    "def calculate_char_level_scores(true_text, pred_text):\n",
    "    # Creating sets of characters for precision, recall, F1\n",
    "    true_chars = set(true_text)\n",
    "    pred_chars = set(pred_text)\n",
    "    \n",
    "    true_positive = len(true_chars & pred_chars)\n",
    "    precision = true_positive / len(pred_chars) if pred_chars else 0\n",
    "    recall = true_positive / len(true_chars) if true_chars else 0\n",
    "    f1 = (2 * precision * recall) / (precision + recall) if precision + recall > 0 else 0\n",
    "    return precision, recall, f1\n",
    "\n",
    "# Calculate character-level scores for each entry\n",
    "df_merged[['char_precision', 'char_recall', 'char_f1']] = df_merged.apply(\n",
    "    lambda row: pd.Series(calculate_char_level_scores(row['text_true'], row['text_pred'])), axis=1\n",
    ")\n",
    "\n",
    "# Aggregate the results\n",
    "average_precision = df_merged['char_precision'].mean()\n",
    "average_recall = df_merged['char_recall'].mean()\n",
    "average_f1_score = df_merged['char_f1'].mean()\n",
    "\n",
    "# Output results\n",
    "print(f\"Accuracy (Exact Match): {accuracy:.2f}\")\n",
    "print(f\"Average Levenshtein Ratio: {average_levenshtein_ratio:.2f}\")\n",
    "print(f\"Character-Level Precision: {average_precision:.2f}\")\n",
    "print(f\"Character-Level Recall: {average_recall:.2f}\")\n",
    "print(f\"Character-Level F1 Score: {average_f1_score:.2f}\")\n",
    "\n",
    "df_merged_loaction = f'{output_location}/merged.csv'\n",
    "df_merged.to_csv(df_merged_loaction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plate examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "first_dataset = source_dataset_location\n",
    "second_dataset = scale_dataset_location\n",
    "\n",
    "# start_index = 0\n",
    "start_index = random.randint(0, len(os.listdir(second_dataset)))\n",
    "\n",
    "for img_file in os.listdir(second_dataset)[start_index:start_index+10]:\n",
    "    if img_file.endswith('jpg'):\n",
    "        cropped_img_path = os.path.join(second_dataset, img_file)\n",
    "        source_img_path = os.path.join(first_dataset, img_file[6:])\n",
    "        results_path = os.path.join(results_dir, img_file[:-3]+'json')\n",
    "\n",
    "        cropped_img = cv2.imread(cropped_img_path)\n",
    "        source_img = cv2.imread(source_img_path)\n",
    "        cropped_img_rgb = cv2.cvtColor(cropped_img, cv2.COLOR_BGR2RGB)\n",
    "        source_img_rgb = cv2.cvtColor(source_img, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        with open(results_path, 'r') as f:\n",
    "            results = json.load(f)\n",
    "            for result in results:\n",
    "                print(result)\n",
    "        \n",
    "        # Plot images and results\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "        axes[0].imshow(source_img_rgb)\n",
    "        axes[0].set_title('Source Image')\n",
    "        axes[0].axis('off')\n",
    "        \n",
    "        axes[1].imshow(cropped_img_rgb)\n",
    "        axes[1].set_title('Cropped Image')\n",
    "        axes[1].axis('off')\n",
    "        \n",
    "        plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
