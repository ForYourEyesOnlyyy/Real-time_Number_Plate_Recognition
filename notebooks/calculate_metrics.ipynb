{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "import pandas as pd\n",
    "import pandas as pd\n",
    "from difflib import SequenceMatcher\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_version = 11 # 5 or 11\n",
    "output_csv_names = ['paddle_ocr', 'easy_ocr', 'keras_ocr', 'transformer_ocr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_dir = os.path.dirname(os.getcwd())\n",
    "dataset_location = os.path.join(project_dir, 'data', 'ocr_evaluation')\n",
    "output_location = os.path.join(project_dir, 'data', f'yolo_v{model_version}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>picture_name</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>plate_00808.jpg</th>\n",
       "      <td>046TS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>plate_01433.jpg</th>\n",
       "      <td>912FB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>plate_01063.jpg</th>\n",
       "      <td>044FF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>plate_01576.jpg</th>\n",
       "      <td>M496T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>plate_00263.jpg</th>\n",
       "      <td>155DW</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  text\n",
       "picture_name          \n",
       "plate_00808.jpg  046TS\n",
       "plate_01433.jpg  912FB\n",
       "plate_01063.jpg  044FF\n",
       "plate_01576.jpg  M496T\n",
       "plate_00263.jpg  155DW"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_true_location = f'{dataset_location}/output.csv'\n",
    "df_true = pd.read_csv(df_true_location)\n",
    "df_true['picture_name'] = df_true['picture_name'].apply(lambda x: 'plate_'+x)\n",
    "df_true.set_index('picture_name', inplace=True)\n",
    "df_true.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_metrics(df_pred_name):\n",
    "    df_pred_location = f'{output_location}/{df_pred_name}_pred.csv'\n",
    "    df_pred = pd.read_csv(df_pred_location)\n",
    "    df_pred.set_index('picture_name', inplace=True)\n",
    "    \n",
    "    # Ensure df_true is defined and has the same index\n",
    "    # Assuming df_true is defined elsewhere and set as index 'picture_name'\n",
    "    \n",
    "    # Merging dataframes on 'picture_name' index to only evaluate overlapping entries\n",
    "    df_merged = df_true.join(df_pred, lsuffix='_true', rsuffix='_pred', how='inner')\n",
    "\n",
    "    # 1. Accuracy (Exact Match)\n",
    "    exact_matches = (df_merged['text_true'] == df_merged['text_pred']).sum()\n",
    "    accuracy = exact_matches / len(df_merged)\n",
    "\n",
    "    # 2. Levenshtein Distance (Edit Distance) - Using SequenceMatcher\n",
    "    def levenshtein_ratio(str1, str2):\n",
    "        return SequenceMatcher(None, str(str1), str(str2)).ratio()\n",
    "\n",
    "    # Handle NaN values by converting them to empty strings\n",
    "    df_merged['levenshtein_ratio'] = df_merged.apply(\n",
    "        lambda row: levenshtein_ratio(\n",
    "            str(row.get('text_true', '')), \n",
    "            str(row.get('text_pred', ''))\n",
    "        ), \n",
    "        axis=1\n",
    "    )\n",
    "    average_levenshtein_ratio = df_merged['levenshtein_ratio'].mean()\n",
    "\n",
    "    # 3. Character-Level Precision, Recall, F1 Score\n",
    "    def calculate_char_level_scores(true_text, pred_text):\n",
    "        # Handle NaN values\n",
    "        true_text = str(true_text)\n",
    "        pred_text = str(pred_text)\n",
    "        \n",
    "        # Creating sets of characters for precision, recall, F1\n",
    "        true_chars = set(true_text)\n",
    "        pred_chars = set(pred_text)\n",
    "        \n",
    "        true_positive = len(true_chars & pred_chars)\n",
    "        precision = true_positive / len(pred_chars) if len(pred_chars) > 0 else 0\n",
    "        recall = true_positive / len(true_chars) if len(true_chars) > 0 else 0\n",
    "        f1 = (2 * precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "        return precision, recall, f1\n",
    "\n",
    "    # Calculate character-level scores for each entry\n",
    "    df_merged[['char_precision', 'char_recall', 'char_f1']] = df_merged.apply(\n",
    "        lambda row: pd.Series(calculate_char_level_scores(row['text_true'], row['text_pred'])), \n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    # Aggregate the results\n",
    "    average_precision = df_merged['char_precision'].mean()\n",
    "    average_recall = df_merged['char_recall'].mean()\n",
    "    average_f1_score = df_merged['char_f1'].mean()\n",
    "\n",
    "    # Output results\n",
    "    print(f'Results of {df_pred_name} model')\n",
    "    print('---------------------------------')\n",
    "    print(f\"Accuracy (Exact Match): {accuracy:.2f}\")\n",
    "    print(f\"Average Levenshtein Ratio: {average_levenshtein_ratio:.2f}\")\n",
    "    print(f\"Character-Level Precision: {average_precision:.2f}\")\n",
    "    print(f\"Character-Level Recall: {average_recall:.2f}\")\n",
    "    print(f\"Character-Level F1 Score: {average_f1_score:.2f}\")\n",
    "    print('\\n')\n",
    "\n",
    "    df_merged_location = f'{output_location}/merged_{df_pred_name}.csv'\n",
    "    df_merged.to_csv(df_merged_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results of paddle_ocr model\n",
      "---------------------------------\n",
      "Accuracy (Exact Match): 0.32\n",
      "Average Levenshtein Ratio: 0.70\n",
      "Character-Level Precision: 0.83\n",
      "Character-Level Recall: 0.84\n",
      "Character-Level F1 Score: 0.82\n",
      "\n",
      "\n",
      "Results of easy_ocr model\n",
      "---------------------------------\n",
      "Accuracy (Exact Match): 0.08\n",
      "Average Levenshtein Ratio: 0.41\n",
      "Character-Level Precision: 0.52\n",
      "Character-Level Recall: 0.42\n",
      "Character-Level F1 Score: 0.44\n",
      "\n",
      "\n",
      "Results of keras_ocr model\n",
      "---------------------------------\n",
      "Accuracy (Exact Match): 0.03\n",
      "Average Levenshtein Ratio: 0.46\n",
      "Character-Level Precision: 0.63\n",
      "Character-Level Recall: 0.71\n",
      "Character-Level F1 Score: 0.66\n",
      "\n",
      "\n",
      "Results of transformer_ocr model\n",
      "---------------------------------\n",
      "Accuracy (Exact Match): 0.00\n",
      "Average Levenshtein Ratio: 0.43\n",
      "Character-Level Precision: 0.41\n",
      "Character-Level Recall: 0.55\n",
      "Character-Level F1 Score: 0.46\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for name in output_csv_names:\n",
    "    print_metrics(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
